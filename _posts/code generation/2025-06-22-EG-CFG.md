---
title: "[논문리뷰] Execution Guided Line-by-Line Code Generation"
date: 2025-06-22
last_modified_at: 2025-06-22
categories:
  - 논문리뷰
tags:
  - Code Generation
  - LLM
excerpt: "EG-CFG"
use_math: True
classes: wide
---
> arXiv 2025. [[Paper](https://arxiv.org/abs/2506.10948v1)] 
> [[Page](https://github.com/boazlavon/eg_cfg)]
> Boaz Lavon, Shahar Katz, Lior Wolf
> 12 Jun 2025

## Abstract
Execution-Guided Classifier-Free Guidance (EG-CFG)는 모델이 코드를 생성하는 동안 각 코드 라인마다 line-by-line feedback을 동적으로 반영하여, 실행 가능한 코드를 생성하도록 유도하는 기법이다. 다음 단계들로 구성된다.
- Beam search를 사용해 여러 개의 candidate completion을 생성한다.
- 생성된 코드들을 test case를 이용해 실행해보고 execution signal을 얻는다.
- 얻은 signal을 다음 줄을 생성할 때 프롬프트에 삽입하여, 모델이 더 나은 코드를 생성할 수 있도록 한다.
코드 한 줄을 생성할 때 줄 내에서는 같은 feedback을 바탕으로 코드를 생성하고 라인 단위에서는 새로운 feedback을 반영해서 syntax는 유지하면서 실행 가능한 코드를 작성할 수 있도록 가이드를 제공한다. 병렬 처리를 통해 task level에서 여러 개의 reasoning path를 거쳐 candidate solution을 생성한다.

## Introduction
기존의 LLM을 활용한 code generation은 출력을 보았을 때 잘 작성된 코드처럼 보이지만 실제 코드를 돌려보면 잘 작동하지 않을 때가 많다. 이는 기존의 LLM을 활용한 code generation이 단순히 데이터셋의 정적인 코드 패턴을 학습한 것을 바탕으롴 코드를 생성하기 때문에 runtime behavior를 출력에 반영하지 못하기 때문이다. 이러한 문제를 해결하기 위해 기존 연구는 iterative refinement, self-debugging등의 방식을 활용하여 test case를 통과하지 못한 경우 코드를 재생성하거나 여러 개의 agent를 사용하여 코드를 개선하는 방식을 활용하고 있다. 하지만 이러한 방식 모두 candidate solution (완성된 코드) 를 생성하고, 실행하고, 결과를 feedback으로 활용하여 재시도하는 방식을 활용하고 있다. 그러므로, inference과정에서는 runtime behavoir를 반영하지 못하기 때문에 코드를 생성하는 과정에서 correct한 방향으로 가이드하기는 어려운 방식이 된다. 

실제 사람이 코딩할 때는 부분부분 코드를 작성하면서 실행해보고 수정하는 과정을 거치며 코드를 완성한다. 전체 구조나 문법적인 추론뿐만 아니라 중간 중간 코드가 어떻게 작동하는지를 살펴보면서 코드를 작성함을 의미한다. EG-CFG는 이러한 인간의 사고과정과 유사하게 decoding temperature를 조절해 reasoning path를 넓게 탐색해 다양한 horizon의 candidate를 생성해서 얻은 feedback을 이용해 코드를 완성한다.

기존 방식들은 scalar pass/fail, ranking signal, verbal critique, structured reflection 등의 성공 여부를 나타내는 feedback을 활용한 것과 달리 EG-CFG는 실행결과를 바로 feedback으로 활용했다. 이를 통해 모델이 스스로 결과를 해석한 뒤 생성 feedback으로 활용하게 된다.

## Related Work
- 이전 연구들은 전체 solution을 완성하고 execution feedback을 활용한 반면, EG-CFG는 line별로 feedback을 받는다.
- pass/fail signal과 같은 explicit supervision없이 implicit feedback만 이용해서 코드를 생성한다.
- 각 agent는 개별적인 parameter를 가지고 각자의 reasoning path로 task를 해결한다 => task level parallelism
- 이전에 사용된 적 없던 Classifier-Free Guidance를 활용하고 있다.

## Method

$$ p_{inst}=(p_0, p_{task}, T, f_{name})$$

프로그래밍 task는 위와 같이 $p_0$ (자연어 instruction), $p_{task}$ (task 정의), $T = \\{ t_j \\}\_{j=1}^{\vert T \vert}$ (test case 집합), $f_{name}$ (Python 함수 이름) 의 튜플로 정의된다. Code generation은 다음 조건을 만족하고 실행 가능한 Python 코드 $w^\*=[w\_0^\*, w\_1^\*,\cdots,w^\*\_{N-1}]$ 를 생성하는 것이다:

$$ Execute(w^*,t_j)=\text{success},\quad\quad\forall t_j\in T$$

각 step $i$까지 생성된 token sequence를 $w\_{<i}$라고 할때, 모델 $M$은 distribution  $M(w_i\vert p_{inst, w<i})$ 를 할당 받아 다음 token을 생성한다. 이 과정을 end-of-code token을 생성하거나, 최대 길이 $N_{max}$에 도달할 때까지 반복한다.

Instruction template은 DeepSeek-Coder- 3-shot prompt (instruction + 예제 3개)의 형식을 활용하거나, step-by-step 생성이 가능하도록 constraint나 세부적인 로직이 포함된 instruction-only template을 활용한다. 즉 $p_0$는 두 가지가 있다.

$$w_i^{pre}=argmaxM(w_i\vert p_{inst, w<i}),\quad\quad p_{pre}=[p_{inst},w_{pre}^0,\cdots,w_{pre}^{n-1}]$$

모델을 이용해 초기 solution $p_{pre}$를 생성한다. 두 가지 위치를 함께 기억해놓는데 첫 번째는 $p_0$에 정의된 start-of-code token의 position을 $i_{solution}$으로 저장해놓고, 두 번째로 $p_{inst}$에서 example들의 마지막 token의 index $i_{dyn}$을 저장해놓는다. 두 번째 index는 signal을 prompt에 삽입할 때 이용한다. $p_{pre}$에 코드 token을 삽입한 prompt $p_{sol}$을 LLM에 입력으로 넣어 코드를 생성한다. 재귀적으로 partial solution을 prompt에 포함시키면서 최종 코드를 생성한다.

### Dynamic Execution Feedback
Prompt $p_{sol}$이 주어졌을 때, Beam-search를 이용하여 $s$개의 candidate를 생성한다. 이때 $d$는 생성할 코드의 길이, $t$는 decoding temperature를 의미한다.

$$c^j \sim M(p_{sol};d,t),\quad\quad j=1,\dots,s$$

위 candidate를 이용하여 다음 inference에 이용할 execution signal을 생성한다.

**Executable Extraction** 생성된 코드에서 먼저 실행 가능한 component를 추출한다.

$$\hat{c}^j=ExtractExecutable(c^j),\quad\quad j=1,\dots,s$$

추출하는 과정은 다음과 같다.
- candidate $c_j$에 대해 AST (Abstract Syntax Tree) parsing을 시도한다.
- 실패한 경우 마지막 줄에 `pass` statement를 삽입하고 다시 parsing해본다.
- 그래도 실패한 경우, 마지막 줄을 지우고 다시 parsing해본다.
위 과정을 반복해서, 지금까지 생성한 코드를 최소한으로 변화시키면서 문법적으로 valid하고 실행가능한 component를 추출한다. 추출한 후에 중복을 제거한다.

$$ C=Unique(\{\hat{c}^j\}^s_{j=1}) $$

**Execution Feedback and Trace** 이후, 각 test case에 대한 feedback을 생성한다.

$$e^{j,m}=ExtractExecutionFeedback(\hat{c}^j,t_m),\quad\quad\forall\hat{c}^j\in C,t_m\in T$$

각 feedback은 다음으로 구성된다.
- Executed lines of code
- Variable States (Values & Types)
- Function invocations
- Return values
- Detailed descriptions of runtime errors, if they ocur
위와 같이 구성해서 실행한 코드의 correctness와 behavior를 feedback이 충분히 포함하도록 한다.

**Dynamic Signal Aggregation** 
위의 feedback을 이용해 dynamic signal prompt를 구성한다.

$$ p_{signal}=[p_{dyn-inst},\{(\hat{c}^j,t_m,e^{j,m})\}_{\hat{c}^j\in C, t_m\in T}]$$

$p_{dyn-inst}$는 instruction string이고, 각 tuple은 unique candidate, test case, feedback으로 구성되어 있다. dynamic signal prompt를 이용해 LLM에게 넘겨줄 guidance prompt $p_{dyn}$을 생성한다.

$$p_{dyn}=[p_{sol}[:i_{dyn}],p_{signal},p_{sol}[i_{dyn}:]]$$

![Dynamic prompt](/assets/img/EG-CFG/dynamic.webp)

### Classifier-Free Gudiance
Classifer-Free Guidance [[Paper](https://arxiv.org/abs/2207.12598)]와 유사하게 prior distribution과 execution feedback으로 conditioning한 distribution을 결합하여 token을 생성한다.

$$\log M_{CFG}(w_i\vert p_{sol},p_{dyn})=\log M(w_i\vert p_{sol}) + \gamma[\log M(w_i\vert p_{dyn})-\log M(w_i\vert p_{sol})]$$

식에서 알 수 있듯이, $\gamma$ 값이 커질수록 생성 과정이 execution-based guidance를 더 따라가게 될 것이다. 반대로 작을수록 prior를 따라가게 된다.

### Execution-Guided Inference Loop
Token generation step:

$$w^i_{sol}=argmaxM_{CFG}(w_i\vert p_{sol},p_{dyn}),\quad\quad p_{sol}=[p_{pre},w_{sol}^0,\cdots,w_{sol}^{n-1}]$$

초기 prompt는 $p_{pre}$를 이용한다. 각 token을 생성할 때마다 prior $p_{sol}$과 conditioned distribution $p_{dyn}$을 이용하여 token을 생성한다. (CFG) 하나의 line을 다 생성할 때마다 $p_{dyn}$을 재생성한다. 

주어진 input task $\tau=(p_{inst}, T,f_{name})$에 대하여, 각 parameter combination $(s,d,t,\text{instruction prompt type})$마다 CFG strength $\gamma$를 증가시키면서 코드를 반복적으로 생성한다. 만약 correct solution을 찾은 경우 return하고 그렇지 않은 경우 다른 paramter combination을 이용해 같은 과정을 진행한다.

## Experiments
**MBPP**
![MBPP](/assets/img/EG-CFG/mbpp.webp)
**HumanEval**
![HumanEval](/assets/img/EG-CFG/HumanEval.webp)
**CodeContest**
![CodeContest](/assets/img/EG-CFG/CodeContest.webp)
**Runtime**
![Runtime](/assets/img/EG-CFG/runtime.webp)
각 paramter combination마다 병렬적으로 코드를 생성할 수 있고 특정 paramter combination에서 성공적으로 코드를 생성하면 나머지는 종료하면 되니 효율적으로 코드 생성이 가능하다.

**Ablation Study**
![abl](/assets/img/EG-CFG/abl.webp)
Beam search, CFG를 사용한 것이 성능 향상에 기여했음을 확인할 수 있다. 마지막으로 feedback을 제공할 때 단순히 variable의 value/type만 제공한 경우 성능이 떨어짐도 확인할 수 있다.

## Limitations & Directions
- Computational overhead (beam search, multiple candidate executions, CFG (dual distribution))
- Not applicable w/o appopriate test cases
- Not exploit task decomposition [[MGDebugger](https://arxiv.org/abs/2410.01215)], not top-down problem-inspection [[AEI](https://arxiv.org/abs/2412.02441)]
- Longer-horizon planning, multi-file interactions
