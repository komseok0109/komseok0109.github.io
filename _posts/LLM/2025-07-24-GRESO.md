---
title: "[논문리뷰]Act Only When It Pays: Efficient Reinforcement Learning for LLM Reasoning via Selective Rollouts"
date: 2025-07-24
last_modified_at: 2025-07-24
categories:
  - 논문리뷰
tags:
  - Reinforcement Learning
  - Reasoning
  - LLM
excerpt: "GRESO"
use_math: True
classes: wide
---
> arXiv 2025. [[Paper](https://arxiv.org/abs/2506.02177)] [[Code](https://github.com/Infini-AI-Lab/GRESO)]
> 2 Jun 2025

특정 prompt에서 생성되는 response들의 reward가 모두 동일한 경우 advantage가 0이라서 학습에 전혀 도움이 되지 않는다. 이를 해결하기 위해 [DAPO](https://arxiv.org/abs/2503.14476)는 dynamic sampling을 도입했으나 rollout 이후에 검증하는 것이기 때문에 overhead가 크다. 다음 세 가지 조건을 만족해야한다.

- Online data selection: training 과정에서 선별할 수 있어야 한다. Offline에서 fine-tuning된 모델을 이용해 dataset pruning을 하는 것은 그만큼 cost가 발생하기 때문이다.
- Model-based data value estimation: 모델/training stage에 맞게 dynamic하게 data의 value를 측정하는 방법이 필요하다. (어떤 data가 informative한지, 학습에 도움이 되는지)
- Low Computational Overhead: overhead가 적어야 한다.

# Observations related to zero-variance prompts
특정 prompt에 대해서 생성한 response의 reward가 variance, advantage 모두 0이 되기 때문에 해당 prompt는 더 이상 학습에 도움이 되지 않는다. 이를 zero-variance prompt라 하고 반대의 경우를 effective prompt 라고 부르기로 한다.

![](/assets/img/GRESO/ob1.webp)

위 그래프에서 확인할 수 있듯이 effective prompt의 비율이 학습을 할수록 감소한다. 이는 가면 갈수록 학습에 의미없는 rollout이 생성되고 있다는 이야기이고 효율성 측면에서 좋지 못하다. DAPO는 dynamic sampling을 도입해서 문제를 해결했고 성능/효율성 모두 개선했다. 이는 zero-variance prompt를 제거하는 것이 성능/효율성 모두 개선하는데 효과가 있음을 증명한다. 하지만, dynamis sampling은 기존 GRPO 보다는 효율적이지만 oversampling cost가 발생한다. Rollout을 생성하기 전에 prompt만 보고 이를 확인할 수 있다면 더 효율적인 학습이 가능할 것이다.

또, training data는 epoch 간에 temporal correlation이 존재하는 것은 이미 잘 알려져 있다. 본 논문에서는 zero-variance prompt도 비슷한 특성을 지닐 것으로 예상해서 이를 확인해보고 있다. 다음 두 가지 값을 조사해본다.

- $P(Previous\vert Current)$: 현재 epoch에서 zero variance prompt가 이전 epoch에서도 zero variance prompt일 확률 
- $P(Current\vert Previous)$: 이전 epoch에서 zero variance prompt가 현재 epoch에서도 zero variance prompt일 확률 

![](/assets/img/GRESO/ob2.webp)

- 주황색 그래프에서 확인할 수 있듯이  현재 epoch에서 zero-variance인 경우 이전 epoch에서도 그러할 확률이 매우 높다.
- 초록색 그래프에서 우리는 이전에 zero-variance prompt였어도 20% 정도는 effective prompt임을 확인할 수 있다. 이는 rollout 과정에서 exploration을 통해 effective prompt로 변환할 수 있는 가능성을 제시하고 있다.
 
# GRPO with Efficient Selective Rollout
![](/assets/img/GRESO/greso.webp)

위에서 zero-variance prompt는 다음 epoch에서도 zero-variance prompt일 확률이 높은걸 관찰했다. 그래서 epoch마다 training dynamic을 reward하는 방식을 통해 rollout하기 전에 zero-variance prompt를 필터링한다. 